{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ff_train = pd.read_csv(\"tep_faultfree_training.csv\")\n",
    "df_ff_test = pd.read_csv(\"tep_faultfree_testing.csv\")\n",
    "df_f_train = pd.read_csv(\"tep_faulty_training.csv\")\n",
    "df_f_test = pd.read_csv(\"tep_faulty_testing.csv\")\n",
    "\n",
    "df_ff_train[\"label\"] = 0\n",
    "df_f_train[\"label\"] = 1\n",
    "df_ff_test[\"label\"] = 0\n",
    "df_f_test[\"label\"] = 1\n",
    "\n",
    "df_train_combined = pd.concat(\n",
    "    [df_ff_train, df_f_train],\n",
    "    axis=0,          \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_test_combined = pd.concat(\n",
    "    [df_ff_test, df_f_test],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_df(df, scaler):\n",
    "\n",
    "    features_scaled = scaler.transform(df.iloc[:, :55])\n",
    "    labels = df.iloc[:, 55:56].to_numpy().reshape(-1, 1)\n",
    "    X_scaled = np.hstack([features_scaled, labels])\n",
    "    df_scaled = pd.DataFrame(X_scaled, columns=df.columns, index=df.index)\n",
    "\n",
    "    return df_scaled\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_ff_train.iloc[:, :55])\n",
    "df_ff_train = scale_df(df_ff_train, scaler)\n",
    "df_test_combined = scale_df(df_test_combined, scaler)\n",
    "df_train_combined = scale_df(df_train_combined, scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d8d1d",
   "metadata": {},
   "source": [
    "## PCA setup - same as task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = df_ff_train.iloc[:, :55].values\n",
    "y_train = df_ff_train[\"label\"].values\n",
    "\n",
    "X_test = df_test_combined.iloc[:, :55].values\n",
    "y_test = df_test_combined[\"label\"].values\n",
    "\n",
    "pca3 = PCA(n_components=55)\n",
    "pca3.fit(X_train)\n",
    "\n",
    "x = np.arange(1, len(pca3.explained_variance_ratio_[0:-1]) + 2)\n",
    "\n",
    "plt.plot(x,np.cumsum(pca3.explained_variance_ratio_),marker='o')\n",
    "plt.title('Varaiance explained by PCA components')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.xticks(range(1, 56, 5))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance by the first 10 components:\")\n",
    "for i in range(10):\n",
    "    print(f\"PC{i+1}: {pca3.explained_variance_ratio_[i]*100:.2f}%\")\n",
    "\n",
    "\n",
    "pca3 = PCA(n_components=21)\n",
    "pca3.fit(X_train)\n",
    "\n",
    "X_test_pca = pca3.transform(X_test)\n",
    "X_train_pca = pca3.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d2081",
   "metadata": {},
   "source": [
    "## KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 2\n",
    "kmeans = KMeans(n_clusters=k, random_state=69, n_init='auto').fit(X_test_pca)\n",
    "cluster_test = kmeans.predict(X_test_pca)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    X_test_pca[:, 0],\n",
    "    X_test_pca[:, 1],\n",
    "    c=cluster_test,     \n",
    "    cmap='viridis',\n",
    "    s=5,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"K-means clusters in PCA space (PC1 vs PC2)\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cf = confusion_matrix(y_test, cluster_test)\n",
    "# Plot\n",
    "sns.heatmap(cf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix K-means\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, cluster_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b5e49",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe9075",
   "metadata": {},
   "source": [
    "### KNN elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11277929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=20)\n",
    "neighbors_fit = neighbors.fit(X_test_pca)\n",
    "distances, indices = neighbors_fit.kneighbors(X_test_pca)\n",
    "distances = np.sort(distances[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10172c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(distances)\n",
    "plt.title(\"k-distance graph\")\n",
    "plt.xlabel(\"Points sorted by distance\")\n",
    "plt.ylabel(\"20th nearest neighbor distance\")\n",
    "plt.xlim(00000, 115000)\n",
    "plt.ylim(3, 25)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bf8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "eps_values = [3, 3.5, 4, 7, 7.5, 8]\n",
    "\n",
    "results = []  # store results for each eps\n",
    "\n",
    "for eps in eps_values:\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=20, n_jobs=1, algorithm=\"brute\").fit(X_test_pca)\n",
    "    db_labels = db.labels_\n",
    "\n",
    "    # Convert DBSCAN labels: outlier = -1 -> treat as faulty (1)\n",
    "    y_pred = np.where(db_labels == -1, 1, 0)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Compute metrics\n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "    fnr = fn / (fn + tp + 1e-10)\n",
    "    fpr = fp / (fp + tn + 1e-10)\n",
    "\n",
    "    outliers = np.sum(db_labels == -1)\n",
    "    ratio_outliers = outliers / (np.sum(y_test == 1) + 1e-10)\n",
    "\n",
    "    results.append({\n",
    "        \"eps\": eps,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"fnr\": fnr,\n",
    "        \"fpr\": fpr,\n",
    "        \"outliers\": outliers,\n",
    "        \"outlier_ratio\": ratio_outliers\n",
    "    })\n",
    "\n",
    "# Sort by the metric you care about: choose f1 here\n",
    "top3 = sorted(results, key=lambda x: x[\"f1\"], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3422da",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_values = [3, 3.2, 3.4, 3.6, 3.8, 4]\n",
    "min_samples_list = [10, 15, 20, 25]\n",
    "\n",
    "results = []  # store results for each eps\n",
    "\n",
    "for eps in eps_values:\n",
    "        \n",
    "    for min_samples in min_samples_list:\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=1, algorithm=\"brute\").fit(X_test_pca)\n",
    "        db_labels = db.labels_\n",
    "\n",
    "        # Convert DBSCAN labels: outlier = -1 -> treat as faulty (1)\n",
    "        y_pred = np.where(db_labels == -1, 1, 0)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        # Compute metrics\n",
    "        precision = tp / (tp + fp + 1e-10)\n",
    "        recall = tp / (tp + fn + 1e-10)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "        fnr = fn / (fn + tp + 1e-10)\n",
    "        fpr = fp / (fp + tn + 1e-10)\n",
    "\n",
    "        outliers = np.sum(db_labels == -1)\n",
    "        ratio_outliers = outliers / (np.sum(y_test == 1) + 1e-10)\n",
    "\n",
    "        results.append({\n",
    "            \"eps\": eps,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"fnr\": fnr,\n",
    "            \"fpr\": fpr,\n",
    "            \"outliers\": outliers,\n",
    "            \"outlier_ratio\": ratio_outliers\n",
    "        })\n",
    "\n",
    "# Sort by the metric you care about: choose f1 here\n",
    "top3 = sorted(results, key=lambda x: x[\"f1\"], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc9ddb",
   "metadata": {},
   "source": [
    "### PLots and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b05502",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers = np.sum(db_labels == -1)\n",
    "n_clusters = len(set(db_labels)) - (1 if -1 in db_labels else 0)\n",
    "\n",
    "print(\"Cluster:\", n_clusters)\n",
    "print(\"Outliers:\", n_outliers)\n",
    "print(\"Split outliers:\", round(n_outliers / len(db_labels) * 100, 2), \"%\")\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(\n",
    "    X_test_pca[:,0],\n",
    "    X_test_pca[:,1],\n",
    "    c=db_labels,\n",
    "    cmap=\"tab10\",\n",
    "    s=5,\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.title(\"DBSCAN clusters in PCA space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "colors = np.where(db_labels == -1, \"black\", \"red\")\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_test_pca[:,0], X_test_pca[:,1], c=colors, s=5, alpha=0.5)\n",
    "plt.title(\"Outliers detected by DBSCAN\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# true labels: 0 = normal, 1 = fault\n",
    "faults = df_test_combined[\"label\"] == 1\n",
    "normals = df_test_combined[\"label\"] == 0\n",
    "outliers = df_test_combined[\"dbscan\"] == -1\n",
    "\n",
    "fault_detection_rate = np.mean(outliers[faults]) * 100\n",
    "false_alarm_rate = np.mean(outliers[normals]) * 100\n",
    "\n",
    "print(\"Fault detection rate:\", round(fault_detection_rate, 2), \"%\")\n",
    "print(\"False alarm rate:\", round(false_alarm_rate, 2), \"%\")\n",
    "\n",
    "pred = np.where(db_labels == -1, 1, 0)\n",
    "\n",
    "cf= confusion_matrix(y_test, pred)\n",
    "sns.heatmap(cf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix DBSCAN\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "colors = np.where(db_labels == -1, \"black\", np.where(y_test==1, \"red\", \"blue\"))\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_test_pca[:,0], X_test_pca[:,1], c=colors, s=5, alpha=0.5)\n",
    "plt.title(\"DBSCAN Outlier Detection vs True Labels\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06b134",
   "metadata": {},
   "source": [
    "## HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN\n",
    "hdb = HDBSCAN(\n",
    "            min_cluster_size=50,      \n",
    "            min_samples=20,           \n",
    "            cluster_selection_epsilon=0.0\n",
    ")\n",
    "hdb_labels = hdb.fit_predict(X_test_pca)   # -1 = outlier\n",
    "df_test_combined[\"hdbscan\"] = hdb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23147428",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = df_test_combined[\"hdbscan\"] == -1\n",
    "faults   = df_test_combined[\"label\"] == 1\n",
    "\n",
    "print(\"Faults detected as outliers:\", \n",
    "      np.mean(outliers[faults]) * 100, \"%\")\n",
    "\n",
    "print(\"Normal detected as outliers:\",\n",
    "      np.mean(outliers[~faults]) * 100, \"%\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(\n",
    "      X_test_pca[:,0], X_test_pca[:,1],\n",
    "      c=df_test_combined[\"hdbscan\"],\n",
    "      cmap='tab10', s=5, alpha=0.5\n",
    ")\n",
    "plt.title(\"HDBSCAN clustering in PCA space\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "labels = df_test_combined[\"hdbscan\"]\n",
    "colors = np.where(labels == -1, \"black\",\"red\")\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_test_pca[:,0], X_test_pca[:,1], c=colors, s=5, alpha=0.5)\n",
    "plt.title(\"Outliers detected by HDBSCAN\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
